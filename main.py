import pandas as pd
import numpy as np
from hmmlearn import hmm
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
import talib
from datetime import datetime
from sklearn.metrics import accuracy_score
from xgboost import XGBClassifier
from skopt import BayesSearchCV
from skopt.space import Real, Integer, Categorical
from xgboost import plot_importance
from imblearn.over_sampling import SMOTE
from imblearn.pipeline import Pipeline as ImbPipeline
from sklearn.model_selection import TimeSeriesSplit
import pickle
import requests
from requests.exceptions import ConnectionError, Timeout, TooManyRedirects
import json
import time
import urllib.parse
import hashlib
import hmac
from scipy.signal import argrelextrema
import math

pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', None)

api_key = 'IbIgJihiEgl4rEjWnOFazg7F4YVzJXVG8if3iKcGsurgspgblDN2F73XMPdUzOcH'

def load_and_preprocess_data(filepath, window_size=2):
    print(f"Loading data from {filepath}...")
    df = pd.read_csv(filepath, names=['Index', 'Timestamp', 'Open', 'High', 'Low', 'Close', 'Volume', 'Label'])
    df.drop(['Index'], axis=1, inplace=True)
    df.drop(0, inplace=True)
    #Drop useless row
    df = df.astype(float)

    df["Returns"] = df["Close"].pct_change()
    df["Volatility"] = df["Returns"].rolling(window=24).std()

    #Replaces 0's with a number close to 0 to avoid infinity being present in Volume_Change
    #Since the label column has 0's present, we need to make sure that they are not replaced
    df['Volume'] = df['Volume'].replace(0, 0.00000000000000001)
    df["Volume_Change"] = df["Volume"].pct_change()

    # Need this because there was a weird error were the data in these columns were not classified as floats, this caused a problem with the pipeline as I'm not using a target encoder
    df['Volume'] = pd.to_numeric(df['Volume'], errors='coerce')
    df['Returns'] = pd.to_numeric(df['Returns'], errors='coerce')

    df['OBV'] = talib.OBV(df['Close'], df['Volume'])

    df['MFV'] = (((df['Close'] - df['Low']) - (df['High'] - df['Close']) / (df['High'] - df['Low'])) * df['Volume'])
    df['MFV'] = df['MFV'].fillna(0) #need this incase nans are generated by dividing by 0
    df['A/D'] = 0
    for i in range(2, len(df)):
        currentMFV = df.loc[i, 'MFV']
        df.loc[i, 'A/D'] = df.loc[i-1, 'A/D'] + currentMFV
    df['CMF'] = df['MFV'].rolling(window=21).sum() / df['Volume'].rolling(window=21).sum()

    df['CumulativeVolume'] = 0
    for i in range(2, len(df)):
        new_volume = df.loc[i-1, 'CumulativeVolume'] + df.loc[i, 'Volume']
        df.loc[i, 'CumulativeVolume'] = new_volume
        if i % 97 == 0: #reset the cumulative volume everyday
            df.loc[i, 'CumulativeVolume'] = df.loc[i, 'Volume']

    df['VWAP'] = (((df['High'] + df['Low'] + df['Close']) / 3) * df['Volume']) / df['CumulativeVolume']

    df['LOW_EMA'] = talib.EMA(df['Close'], timeperiod=9)
    df['HIGH_EMA'] = talib.EMA(df['Close'], timeperiod=21)
    df['RSI'] = talib.RSI(df['Close'], timeperiod=14)
    df['Aroon'] = talib.AROONOSC(df['High'], df['Low'], timeperiod=14)
    df['Fast_%K'], df['Fast_%D'] = talib.STOCHF(df['High'], df['Low'], df['Close'], fastk_period=14)
    df['WILLR'] = talib.WILLR(df['High'], df['Low'], df['Close'])
    df['CCI'] = talib.CCI(df['High'], df['Low'], df['Close'])
    df['ATR'] = talib.ATR(df['High'], df['Low'], df['Close'])
    df['ADX'] = talib.ADX(df['High'], df['Low'], df['Close'])

    df['Momentum'] = df['Close'].diff()
    df['Absolute_Momentum'] = df['Momentum'].abs()
    df['Short_EMA_Momentum'] = talib.EMA(df['Momentum'], timeperiod=13)
    df['Short_EMA_Absolute'] = talib.EMA(df['Absolute_Momentum'], timeperiod=13)
    df['Double_EMA_Momentum'] = talib.EMA(df['Short_EMA_Momentum'], timeperiod=25)
    df['Double_EMA_Absolute'] = talib.EMA(df['Short_EMA_Absolute'], timeperiod=25)
    df['TSI'] = 100 * (df['Double_EMA_Momentum'] / df['Double_EMA_Absolute'])

    df['BB_Upper'], df['BB_Middle'], df['BB_Lower'] = talib.BBANDS(df['Close'], 20)
    df['BB_Width'] = df['BB_Upper'] - df['BB_Lower']

    macd, macdsignal, macdhist = talib.MACDFIX(df['Close'])
    df['MACD'] = macd
    df['MACDSignal'] = macdsignal
    df['MACDHist'] = macdhist

    df['PP'] = (df['High'].shift(1) + df['Low'].shift(1) + df['Close'].shift(1)) / 3
    df['R1'] = 2 * df['PP'] - df['Low'].shift(1)
    df['R2'] = df['PP'] + (df['High'].shift(1) - df['Low'].shift(1))
    df['S1'] = 2 * df['PP'] - df['High'].shift(1)
    df['S2'] = df['PP'] - (df['High'].shift(1) - df['Low'].shift(1))

    #Ichimoku Cloud
    df['Tenkan_Sen'] = (df['High'].rolling(window=9).max() + df['Low'].rolling(window=9).min()) / 2
    df['Kijun_Sen'] = (df['High'].rolling(window=26).max() + df['Low'].rolling(window=26).min()) / 2
    df['Senkou_Span_A'] = (df['Tenkan_Sen'] + df['Kijun_Sen']) / 2
    df['Senkou_Span_B'] = (df['High'].rolling(window=52).max() + df['Low'].rolling(window=52).min()) / 2
    df['Chikou_Span'] = df['Close'].shift(-26)

    #Keltner Channels
    df['KC_Middle'] = talib.EMA(df['Close'], timeperiod=20)
    df['KC_Upper'] = df['KC_Middle'] + df['ATR'] * 2
    df['KC_Lower'] = df['KC_Middle'] - df['ATR'] * 2
    df['KC_Width'] = df['KC_Upper'] - df['KC_Lower']

    # Wave analysis
    n = 2
    df['Smoothed_Close'] = df['Close'].rolling(window=n).mean()

    max_indices = argrelextrema(df['Smoothed_Close'].values, np.greater_equal, order=n)[0]
    min_indices = argrelextrema(df['Smoothed_Close'].values, np.less_equal, order=n)[0]

    df['Wave_Amplitude'] = 0
    df['Wave_Direction'] = 0
    df['Wave_Length_Bars'] = 0

    last_peak_idx = 0
    last_trough_idx = 0

    for i in range(len(df)):
        idx = df.index[i]
        current_close = df['Smoothed_Close'].iloc[i]

        if last_trough_idx >= last_peak_idx:  # need this extra condition to make sure the amplitude and length are not overwritten by the peak code block (seperating peaks/troughs)
            trough_close = df['Smoothed_Close'].iloc[last_trough_idx]
            df.loc[idx, 'Wave_Amplitude'] = current_close - trough_close

            bars_length = i - last_trough_idx
            df.loc[idx, 'Wave_Length_Bars'] = bars_length

        if last_peak_idx >= last_trough_idx:
            peak_close = df['Smoothed_Close'].iloc[last_peak_idx]
            df.loc[idx, 'Wave_Amplitude'] = peak_close - current_close

            bars_length = i - last_peak_idx
            df.loc[idx, 'Wave_Length_Bars'] = bars_length

        if i in max_indices:
            df.loc[idx, 'Wave_Direction'] = -1
            last_peak_idx = i

        if i in min_indices:
            df.loc[idx, 'Wave_Direction'] = 1
            last_trough_idx = i

    # calculate extra wave features
    df['Wave_Velocity'] = df['Wave_Amplitude'] / (df['Wave_Length_Bars'] * 15) #need the *15 because these features require the time from the last peak/trough
    df['Wave_Frequency'] = 1 / (df['Wave_Length_Bars'] * 15)
    df['Wave_Sharpness'] = df['Wave_Amplitude'] / ((df['Wave_Length_Bars'] * 15) ** 2)
    df['Wave_Slope'] = df['Wave_Amplitude'] / df['Wave_Length_Bars']
    df['Wave_Energy'] = df['Wave_Amplitude'] ** 2
    df['Wave_Acceleration'] = df['Wave_Slope'].diff() / df['Wave_Length_Bars']
    df['Wave_Strength'] = df['Wave_Slope'] * df['Wave_Direction']
    df['Normalized_Amplitude'] = df['Wave_Amplitude'] / df['Wave_Amplitude'].rolling(window=window_size).mean()
    df['Normalized_Slope'] = df['Wave_Slope'] / df['Wave_Slope'].rolling(window=window_size).mean()

    #calculate interaction features
    df['Volume-ATR'] = df['Volume'] / df['ATR']
    df['VWAP-ATR'] = (df['Close'] - df['VWAP']) / df['ATR']
    df['RSI-MACD'] = df['RSI'] * df['MACD']
    df['Stochastic-RSI'] = df['Fast_%K'] / df['RSI']
    df['BB-KC'] = df['BB_Width'] / df['KC_Width']
    df['Ichimoku_Overlap'] = (df['Close'] - df['Kijun_Sen']) / (df['Senkou_Span_B'] - df['Senkou_Span_A'])
    df['LOW-HIGH_EMA'] = df['LOW_EMA'] / df['HIGH_EMA']

    df.replace([np.inf, -np.inf], 0, inplace=True)
    df.dropna(inplace=True)

    #calculate aggregate features
    df['Close_Mean'] = df['Close'].rolling(window=window_size).mean()
    df['High_Mean'] = df['High'].rolling(window=window_size).mean()
    df['Open_Mean'] = df['Open'].rolling(window=window_size).mean()
    df['Low_Mean'] = df['Low'].rolling(window=window_size).mean()
    df['Volume_Mean'] = df['Volume'].rolling(window=window_size).mean()
    df['OBV_Mean'] = df['OBV'].rolling(window=window_size).mean()
    df['A/D_Mean'] = df['A/D'].rolling(window=window_size).mean()
    df['CMF_Mean'] = df['CMF'].rolling(window=window_size).mean()
    df['VWAP_Mean'] = df['VWAP'].rolling(window=window_size).mean()
    df['Returns_Mean'] = df['Returns'].rolling(window=window_size).mean()
    df['Volatility_Mean'] = df['Volatility'].rolling(window=window_size).mean()
    df['LOW_EMA_Mean'] = df['LOW_EMA'].rolling(window=window_size).mean()
    df['HIGH_EMA_Mean'] = df['HIGH_EMA'].rolling(window=window_size).mean()
    df['RSI_Mean'] = df['RSI'].rolling(window=window_size).mean()
    df['Aroon_Mean'] = df['Aroon'].rolling(window=window_size).mean()
    df['Fast_%K_Mean'] = df['Fast_%K'].rolling(window=window_size).mean()
    df['Fast_%D_Mean'] = df['Fast_%D'].rolling(window=window_size).mean()
    df['WILLR_Mean'] = df['WILLR'].rolling(window=window_size).mean()
    df['CCI_Mean'] = df['CCI'].rolling(window=window_size).mean()
    df['ATR_Mean'] = df['ATR'].rolling(window=window_size).mean()
    df['ADX_Mean'] = df['ADX'].rolling(window=window_size).mean()
    df['TSI_Mean'] = df['TSI'].rolling(window=window_size).mean()
    df['BB_Width_Mean'] = df['BB_Width'].rolling(window=window_size).mean()
    df['BB_Upper_Mean'] = df['BB_Upper'].rolling(window=window_size).mean()
    df['BB_Middle_Mean'] = df['BB_Middle'].rolling(window=window_size).mean()
    df['BB_Lower_Mean'] = df['BB_Lower'].rolling(window=window_size).mean()
    df['MACD_Mean'] = df['MACD'].rolling(window=window_size).mean()
    df['MACDSignal_Mean'] = df['MACDSignal'].rolling(window=window_size).mean()
    df['MACDHist_Mean'] = df['MACDHist'].rolling(window=window_size).mean()
    df['PP_Mean'] = df['PP'].rolling(window=window_size).mean()
    df['S1_Mean'] = df['S1'].rolling(window=window_size).mean()
    df['S2_Mean'] = df['S2'].rolling(window=window_size).mean()
    df['R1_Mean'] = df['R1'].rolling(window=window_size).mean()
    df['R2_Mean'] = df['R2'].rolling(window=window_size).mean()
    df['Tenkan_Sen_Mean'] = df['Tenkan_Sen'].rolling(window=window_size).mean()
    df['Kijun_Sen_Mean'] = df['Kijun_Sen'].rolling(window=window_size).mean()
    df['Senkou_Span_A_Mean'] = df['Senkou_Span_A'].rolling(window=window_size).mean()
    df['Senkou_Span_B_Mean'] = df['Senkou_Span_B'].rolling(window=window_size).mean()
    df['Chikou_Span_Mean'] = df['Chikou_Span'].rolling(window=window_size).mean()
    df['KC_Width_Mean'] = df['KC_Width'].rolling(window=window_size).mean()
    df['KC_Upper_Mean'] = df['KC_Upper'].rolling(window=window_size).mean()
    df['KC_Middle_Mean'] = df['KC_Middle'].rolling(window=window_size).mean()
    df['KC_Lower_Mean'] = df['KC_Lower'].rolling(window=window_size).mean()
    df['Wave_Direction_Mean'] = df['Wave_Direction'].rolling(window=window_size).mean()
    df['Wave_Amplitude_Mean'] = df['Wave_Amplitude'].rolling(window=window_size).mean()
    df['Wave_Velocity_Mean'] = df['Wave_Velocity'].rolling(window=window_size).mean()
    df['Wave_Frequency_Mean'] = df['Wave_Frequency'].rolling(window=window_size).mean()
    df['Wave_Sharpness_Mean'] = df['Wave_Sharpness'].rolling(window=window_size).mean()
    df['Wave_Slope_Mean'] = df['Wave_Slope'].rolling(window=window_size).mean()
    df['Wave_Energy_Mean'] = df['Wave_Energy'].rolling(window=window_size).mean()
    df['Wave_Acceleration_Mean'] = df['Wave_Acceleration'].rolling(window=window_size).mean()
    df['Wave_Strength_Mean'] = df['Wave_Strength'].rolling(window=window_size).mean()
    df['Volume-ATR_Mean'] = df['Volume-ATR'].rolling(window=window_size).mean()
    df['VWAP-ATR_Mean'] = df['VWAP-ATR'].rolling(window=window_size).mean()
    df['RSI-MACD_Mean'] = df['RSI-MACD'].rolling(window=window_size).mean()
    df['Stochastic-RSI_Mean'] = df['Stochastic-RSI'].rolling(window=window_size).mean()
    df['BB-KC_Mean'] = df['BB-KC'].rolling(window=window_size).mean()
    df['Ichimoku_Overlap_Mean'] = df['Ichimoku_Overlap'].rolling(window=window_size).mean()
    df['LOW-HIGH_EMA_Mean'] = df['LOW-HIGH_EMA'].rolling(window=window_size).mean()

    df['Close_Dev'] = df['Close'].rolling(window=window_size).std()
    df['High_Dev'] = df['High'].rolling(window=window_size).std()
    df['Open_Dev'] = df['Open'].rolling(window=window_size).std()
    df['Low_Dev'] = df['Low'].rolling(window=window_size).std()
    df['Volume_Dev'] = df['Volume'].rolling(window=window_size).std()
    df['OBV_Dev'] = df['OBV'].rolling(window=window_size).std()
    df['A/D_Dev'] = df['A/D'].rolling(window=window_size).std()
    df['CMF_Dev'] = df['CMF'].rolling(window=window_size).std()
    df['VWAP_Dev'] = df['VWAP'].rolling(window=window_size).std()
    df['Returns_Dev'] = df['Returns'].rolling(window=window_size).std()
    df['Volatility_Dev'] = df['Volatility'].rolling(window=window_size).std()
    df['LOW_EMA_Dev'] = df['LOW_EMA'].rolling(window=window_size).std()
    df['HIGH_EMA_Dev'] = df['HIGH_EMA'].rolling(window=window_size).std()
    df['RSI_Dev'] = df['RSI'].rolling(window=window_size).std()
    df['Aroon_Dev'] = df['Aroon'].rolling(window=window_size).std()
    df['Fast_%K_Dev'] = df['Fast_%K'].rolling(window=window_size).std()
    df['Fast_%D_Dev'] = df['Fast_%D'].rolling(window=window_size).std()
    df['WILLR_Dev'] = df['WILLR'].rolling(window=window_size).std()
    df['CCI_Dev'] = df['CCI'].rolling(window=window_size).std()
    df['ATR_Dev'] = df['ATR'].rolling(window=window_size).std()
    df['ADX_Dev'] = df['ADX'].rolling(window=window_size).std()
    df['TSI_Dev'] = df['TSI'].rolling(window=window_size).std()
    df['BB_Width_Dev'] = df['BB_Width'].rolling(window=window_size).std()
    df['BB_Upper_Dev'] = df['BB_Upper'].rolling(window=window_size).std()
    df['BB_Middle_Dev'] = df['BB_Middle'].rolling(window=window_size).std()
    df['BB_Lower_Dev'] = df['BB_Lower'].rolling(window=window_size).std()
    df['MACD_Dev'] = df['MACD'].rolling(window=window_size).std()
    df['MACDSignal_Dev'] = df['MACDSignal'].rolling(window=window_size).std()
    df['MACDHist_Dev'] = df['MACDHist'].rolling(window=window_size).std()
    df['PP_Dev'] = df['PP'].rolling(window=window_size).std()
    df['S1_Dev'] = df['S1'].rolling(window=window_size).std()
    df['S2_Dev'] = df['S2'].rolling(window=window_size).std()
    df['R1_Dev'] = df['R1'].rolling(window=window_size).std()
    df['R2_Dev'] = df['R2'].rolling(window=window_size).std()
    df['Tenkan_Sen_Dev'] = df['Tenkan_Sen'].rolling(window=window_size).std()
    df['Kijun_Sen_Dev'] = df['Kijun_Sen'].rolling(window=window_size).std()
    df['Senkou_Span_A_Dev'] = df['Senkou_Span_A'].rolling(window=window_size).std()
    df['Senkou_Span_B_Dev'] = df['Senkou_Span_B'].rolling(window=window_size).std()
    df['Chikou_Span_Dev'] = df['Chikou_Span'].rolling(window=window_size).std()
    df['KC_Width_Dev'] = df['KC_Width'].rolling(window=window_size).std()
    df['KC_Upper_Dev'] = df['KC_Upper'].rolling(window=window_size).std()
    df['KC_Middle_Dev'] = df['KC_Middle'].rolling(window=window_size).std()
    df['KC_Lower_Dev'] = df['KC_Lower'].rolling(window=window_size).std()
    df['Wave_Direction_Dev'] = df['Wave_Direction'].rolling(window=window_size).std()
    df['Wave_Amplitude_Dev'] = df['Wave_Amplitude'].rolling(window=window_size).std()
    df['Wave_Velocity_Dev'] = df['Wave_Velocity'].rolling(window=window_size).std()
    df['Wave_Frequency_Dev'] = df['Wave_Frequency'].rolling(window=window_size).std()
    df['Wave_Sharpness_Dev'] = df['Wave_Sharpness'].rolling(window=window_size).std()
    df['Wave_Slope_Dev'] = df['Wave_Slope'].rolling(window=window_size).std()
    df['Wave_Energy_Dev'] = df['Wave_Energy'].rolling(window=window_size).std()
    df['Wave_Acceleration_Dev'] = df['Wave_Acceleration'].rolling(window=window_size).std()
    df['Wave_Strength_Dev'] = df['Wave_Strength'].rolling(window=window_size).std()
    df['Volume-ATR_Dev'] = df['Volume-ATR'].rolling(window=window_size).std()
    df['VWAP-ATR_Dev'] = df['VWAP-ATR'].rolling(window=window_size).std()
    df['RSI-MACD_Dev'] = df['RSI-MACD'].rolling(window=window_size).std()
    df['Stochastic-RSI_Dev'] = df['Stochastic-RSI'].rolling(window=window_size).std()
    df['BB-KC_Dev'] = df['BB-KC'].rolling(window=window_size).std()
    df['Ichimoku_Overlap_Dev'] = df['Ichimoku_Overlap'].rolling(window=window_size).std()
    df['LOW-HIGH_EMA_Dev'] = df['LOW-HIGH_EMA'].rolling(window=window_size).std()

    df['Close_Drawdown'] = (df['Close'] / df['Close'].rolling(window=window_size).max() - 1).rolling(window=window_size).min()
    df['High_Drawdown'] = (df['High'] / df['High'].rolling(window=window_size).max() - 1).rolling(window=window_size).min()
    df['Open_Drawdown'] = (df['Open'] / df['Open'].rolling(window=window_size).max() - 1).rolling(window=window_size).min()
    df['Low_Drawdown'] = (df['Low'] / df['Low'].rolling(window=window_size).max() - 1).rolling(window=window_size).min()
    df['Volume_Drawdown'] = (df['Volume'] / df['Volume'].rolling(window=window_size).max() - 1).rolling(window=window_size).min()
    df['OBV_Drawdown'] = (df['OBV'] / df['OBV'].rolling(window=window_size).max() - 1).rolling(window=window_size).min()
    df['A/D_Drawdown'] = (df['A/D'] / df['A/D'].rolling(window=window_size).max() - 1).rolling(window=window_size).min()
    df['Volatility_Drawdown'] = (df['Volatility'] / df['Volatility'].rolling(window=window_size).max() - 1).rolling(window=window_size).min()
    df['LOW_EMA_Drawdown'] = (df['LOW_EMA'] / df['LOW_EMA'].rolling(window=window_size).max() - 1).rolling(window=window_size).min()
    df['HIGH_EMA_Drawdown'] = (df['HIGH_EMA'] / df['HIGH_EMA'].rolling(window=window_size).max() - 1).rolling(window=window_size).min()
    df['RSI_Drawdown'] = (df['RSI'] / df['RSI'].rolling(window=window_size).max() - 1).rolling(window=window_size).min()
    df['Fast_%K_Drawdown'] = (df['Fast_%K'] / df['Fast_%K'].rolling(window=window_size).max() - 1).rolling(window=window_size).min()
    df['Fast_%D_Drawdown'] = (df['Fast_%D'] / df['Fast_%D'].rolling(window=window_size).max() - 1).rolling(window=window_size).min()
    df['CCI_Drawdown'] = (df['CCI'] / df['CCI'].rolling(window=window_size).max() - 1).rolling(window=window_size).min()
    df['ATR_Drawdown'] = (df['ATR'] / df['ATR'].rolling(window=window_size).max() - 1).rolling(window=window_size).min()
    df['ADX_Drawdown'] = (df['ADX'] / df['ADX'].rolling(window=window_size).max() - 1).rolling(window=window_size).min()
    df['TSI_Drawdown'] = (df['TSI'] / df['TSI'].rolling(window=window_size).max() - 1).rolling(window=window_size).min()
    df['BB_Width_Drawdown'] = (df['BB_Width'] / df['BB_Width'].rolling(window=window_size).max() - 1).rolling(window=window_size).min()
    df['BB_Upper_Drawdown'] = (df['BB_Upper'] / df['BB_Upper'].rolling(window=window_size).max() - 1).rolling(window=window_size).min()
    df['BB_Middle_Drawdown'] = (df['BB_Middle'] / df['BB_Middle'].rolling(window=window_size).max() - 1).rolling(window=window_size).min()
    df['BB_Lower_Drawdown'] = (df['BB_Lower'] / df['BB_Lower'].rolling(window=window_size).max() - 1).rolling(window=window_size).min()
    df['MACD_Drawdown'] = (df['MACD'] / df['MACD'].rolling(window=window_size).max() - 1).rolling(window=window_size).min()
    df['MACDSignal_Drawdown'] = (df['MACDSignal'] / df['MACDSignal'].rolling(window=window_size).max() - 1).rolling(window=window_size).min()
    df['MACDHist_Drawdown'] = (df['MACDHist'] / df['MACDHist'].rolling(window=window_size).max() - 1).rolling(window=window_size).min()
    df['PP_Drawdown'] = (df['PP'] / df['PP'].rolling(window=window_size).max() - 1).rolling(window=window_size).min()
    df['S1_Drawdown'] = (df['S1'] / df['S1'].rolling(window=window_size).max() - 1).rolling(window=window_size).min()
    df['S2_Drawdown'] = (df['S2'] / df['S2'].rolling(window=window_size).max() - 1).rolling(window=window_size).min()
    df['R1_Drawdown'] = (df['R1'] / df['R1'].rolling(window=window_size).max() - 1).rolling(window=window_size).min()
    df['R2_Drawdown'] = (df['R2'] / df['R2'].rolling(window=window_size).max() - 1).rolling(window=window_size).min()
    df['Tenkan_Sen_Drawdown'] = (df['Tenkan_Sen'] / df['Tenkan_Sen'].rolling(window=window_size).max() - 1).rolling(window=window_size).min()
    df['Kijun_Sen_Drawdown'] = (df['Kijun_Sen'] / df['Kijun_Sen'].rolling(window=window_size).max() - 1).rolling(window=window_size).min()
    df['Senkou_Span_A_Drawdown'] = (df['Senkou_Span_A'] / df['Senkou_Span_A'].rolling(window=window_size).max() - 1).rolling(window=window_size).min()
    df['Senkou_Span_B_Drawdown'] = (df['Senkou_Span_B'] / df['Senkou_Span_B'].rolling(window=window_size).max() - 1).rolling(window=window_size).min()
    df['Chikou_Span_Drawdown'] = (df['Chikou_Span'] / df['Chikou_Span'].rolling(window=window_size).max() - 1).rolling(window=window_size).min()
    df['KC_Width_Drawdown'] = (df['KC_Width'] / df['KC_Width'].rolling(window=window_size).max() - 1).rolling(window=window_size).min()
    df['KC_Upper_Drawdown'] = (df['KC_Upper'] / df['KC_Upper'].rolling(window=window_size).max() - 1).rolling(window=window_size).min()
    df['KC_Middle_Drawdown'] = (df['KC_Middle'] / df['KC_Middle'].rolling(window=window_size).max() - 1).rolling(window=window_size).min()
    df['KC_Lower_Drawdown'] = (df['KC_Lower'] / df['KC_Lower'].rolling(window=window_size).max() - 1).rolling(window=window_size).min()
    df['Volume-ATR_Drawdown'] = (df['Volume-ATR'] / df['Volume-ATR'].rolling(window=window_size).max() - 1).rolling(window=window_size).min()
    df['VWAP-ATR_Drawdown'] = (df['VWAP-ATR'] / df['VWAP-ATR'].rolling(window=window_size).max() - 1).rolling(window=window_size).min()
    df['RSI-MACD_Drawdown'] = (df['RSI-MACD'] / df['RSI-MACD'].rolling(window=window_size).max() - 1).rolling(window=window_size).min()
    df['BB-KC_Drawdown'] = (df['BB-KC'] / df['BB-KC'].rolling(window=window_size).max() - 1).rolling(window=window_size).min()
    df['LOW-HIGH_EMA_Drawdown'] = (df['LOW-HIGH_EMA'] / df['LOW-HIGH_EMA'].rolling(window=window_size).max() - 1).rolling(window=window_size).min()

    df['Fast_%K_Drawdown'] = df['Fast_%K_Drawdown'].fillna(0)

    df.dropna(inplace=True)
    #defragmenting dataframe
    df = df.copy()

    training_df = df[(df.index >= 68797)] #January 1st 2023 12am
    eval_df = df[((df.index >= 33757) & (df.index <= 48249))] #January 1st 2022 12am to June 1st 2022 12am
    out_of_training_df = df[((df.index >= 48250) & (df.index <= 68796))] #June 1st 2022 12:15am to January 1st 2023 12:15am

    return training_df, eval_df, out_of_training_df

def train_hmm(data, features, scaler, n_components=3):
    print(f"Training HMM with {n_components} components...")
    X = data[features].values

    print("Normalizing features...")
    X_scaled = scaler.fit_transform(X)

    print("Fitting HMM model...")
    model = hmm.GaussianHMM(n_components=n_components, covariance_type='full', n_iter=500, random_state=42, verbose=True)
    model.fit(X_scaled)

    print("HMM training complete")

    filepath = "hmm_model.pkl"
    with open("hmm_model.pkl", "wb") as f:
        pickle.dump(model, f)

    return filepath

def load_hmm(filepath):
    with open(filepath, "rb") as f:
        model = pickle.load(f)
    return model

def predict_states(model, data, features, scaler):
     X = data[features].values
     X_scaled = scaler.transform(X)
     states = model.predict(X_scaled)
     print(f"States precicted. Unique states: {np.unique(states)}")
     return states

def plot_results_hmm(data, states, n_components):
    print("Plotting results...")
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15,10), sharex=True)

    ax1.plot(data.index, data['Close'])
    ax1.set_title('Bitcoin Price and HMM States')
    ax1.set_ylabel('Price')

    for state in range(n_components):
        mask = (states == state)
        ax1.fill_between(data.index, data['Close'].min(), data['Close'].max(), where=mask, alpha=0.3, label=f'State {state}')
    ax1.legend()

    ax2.plot(data.index, data['Returns'])
    ax2.set_title('Bitcoin Returns')
    ax2.set_ylabel('Returns')
    ax2.set_xlabel('Date')

    plt.tight_layout()
    print("Saving plot...")
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")
    plt.savefig('plots/hmm' + str(timestamp))

def plot_results_rf(data, labels_true, labels_pred):
    print("Plotting results...")
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15,10), sharex=True)

    ax1.plot(data.index, data['Close'])
    ax1.set_title('Bitcoin Price and Real Labels')
    ax1.set_ylabel('Price')

    for label in range(3):
        mask = (labels_true == label)
        ax1.fill_between(data.index, data['Close'].min(), data['Close'].max(), where=mask, alpha=0.3, label=f'Signal {label}')
    ax1.legend()

    ax2.plot(data.index, data['Close'])
    ax2.set_title('Bitcoin Price and Predicted Labels')
    ax2.set_ylabel('Price')

    for label in range(3):
        mask = (labels_pred == label)
        ax2.fill_between(data.index, data['Close'].min(), data['Close'].max(), where=mask, alpha=0.3, label=f'Signal {label}')
    ax2.legend()

    plt.tight_layout()
    print("Saving plot...")
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")
    plt.savefig('plots/rf' + str(timestamp))

def train_xgboost(data_train, labels_train, data_test, labels_test, splits, iters):
    tscv = TimeSeriesSplit(n_splits=splits)

    pipeline = ImbPipeline(steps=[
        ('smote', SMOTE(random_state=42)),
        ('xgb', XGBClassifier(random_state=42, eval_metric='mlogloss', early_stopping_rounds=40, tree_method='hist', device='cuda', predictor='gpu_predictor'))
    ])

    search_space = {
        'xgb__max_depth': Integer(1, 6),
        'xgb__learning_rate': Real(0.001, 1.0, prior='log-uniform'),
        'xgb__subsample': Real(0.3, 1.0),
        'xgb__colsample_bytree': Real(0.5, 1.0),
        'xgb__colsample_bylevel': Real(0.5, 1.0),
        'xgb__colsample_bynode': Real(0.5, 1.0),
        'xgb__reg_alpha': Real(0.0, 8.0),
        'xgb__reg_lambda': Real(0.0, 13.0),
        'xgb__gamma': Real(0.0, 12.0),
        'xgb__n_estimators': Integer(100, 2000),
        'xgb__min_child_weight': Integer(1, 15),
        'xgb__scale_pos_weight': Real(0.0, 10.0),
        'xgb__max_bin': Integer(128, 512),
        'xgb__grow_policy': Categorical(["depthwise", "lossguide"]),
        'xgb__max_delta_step': Integer(0, 10)
    }
    opt = BayesSearchCV(pipeline, search_space, cv=tscv, n_iter=iters, scoring='balanced_accuracy', random_state=42)

    opt.fit(data_train, labels_train, xgb__eval_set=[(data_test, labels_test)])
    print("Best estimator: ", opt.best_estimator_)
    print("Best score: ", opt.best_score_)
    print("Best params: ", opt.best_params_)
    print(opt.score(data_test, labels_test))
    labels_pred = opt.predict(data_test)
    labels_pred = labels_pred.tolist()
    print(labels_pred.count(0))
    print(labels_pred.count(1))
    print(labels_pred.count(2))

    xgboost_step = opt.best_estimator_.steps[1]
    xgboost_model = xgboost_step[1]
    plot_importance(xgboost_model, max_num_features=100)
    plt.show()

    #save the model
    filepath = "xgboost_pipeline.pkl"
    with open(filepath, "wb") as f:
        pickle.dump(opt.best_estimator_, f)

    return filepath

def load_xgboost(filepath):
    with open(filepath, "rb") as f:
        model = pickle.load(f)
    return model

def get_binanceus_signature(data, secret):
    postdata = urllib.parse.urlencode(data)
    message = postdata.encode()
    byte_key = bytes(secret, 'UTF-8')
    mac = hmac.new(byte_key, message, hashlib.sha256).hexdigest()
    return mac

def exchange_btc(side, quoteOrderQty):
    data = {
        "symbol": 'BTCUSDC',
        "side": side,
        "type": 'MARKET',
        "quoteOrderQty": quoteOrderQty,
        "timestamp": int(round(time.time() * 1000))
    }
    headers = {
        'X-MBX-APIKEY': api_key
    }
    signature = get_binanceus_signature(data, api_sec)
    payload = {
        **data,
        "signature": signature,
    }
    req = requests.post(('https://api.binance.us/api/v3/order'), headers=headers, data=payload)
    return req.text

def get_historical_data(start_time, end_time):
    url = 'https://api.binance.us/api/v3/klines'
    headers = {
        'X-MBX-APIKEY': api_key,
    }
    parameters = {
        'symbol': 'BTCUSDC',
        'interval': '15m',
        'startTime': str(start_time),
        'limit': '1000'
    }

    flag = True
    dataframes = []
    session = requests.Session()
    while(flag):
        session.headers.update(headers)

        try:
            response = session.get(url, params=parameters)
            data = json.loads(response.text)
        except (ConnectionError, requests.Timeout, requests.TooManyRedirects) as e:
            print(e)

        df = pd.DataFrame(columns=["Timestamp", "Open", "High", "Low", "Close", "Volume"])

        for i in range(len(data)):
            df.loc[len(df)] = {"Timestamp": int(data[i][0]),
                               "Open": float(data[i][1]),
                               "High": float(data[i][2]),
                               "Low": float(data[i][3]),
                               "Close": float(data[i][4]),
                               "Volume": float(data[i][5])}
            close_time = int(data[i][6])

            if close_time >= end_time:
                flag = False
        dataframes.append(df)

        start_time += (1000*15*60000) #add time in milliseconds
        parameters['startTime'] = start_time #update time

    combined_df = pd.concat(dataframes, ignore_index=True)
    return combined_df

def calculate_indicators(df, window_size=2):
    df["Returns"] = df["Close"].pct_change()
    df["Volatility"] = df["Returns"].rolling(window=24).std()

    df["Volume"] = df["Volume"].replace(0, 0.00000000000000001)
    df["Volume_Change"] = df["Volume"].pct_change()
    df['OBV'] = talib.OBV(df['Close'], df['Volume'])

    df['MFV'] = (((df['Close'] - df['Low']) - (df['High'] - df['Close']) / (df['High'] - df['Low'])) * df['Volume'])
    df['MFV'] = df['MFV'].fillna(0)  # need this incase nans are generated by dividing by 0
    df['A/D'] = 0
    for i in range(2, len(df)):
        currentMFV = df.loc[i, 'MFV']
        df.loc[i, 'A/D'] = df.loc[i - 1, 'A/D'] + currentMFV
    df['CMF'] = df['MFV'].rolling(window=21).sum() / df['Volume'].rolling(window=21).sum()

    df['CumulativeVolume'] = 0
    for i in range(2, len(df)):
        new_volume = df.loc[i - 1, 'CumulativeVolume'] + df.loc[i, 'Volume']
        df.loc[i, 'CumulativeVolume'] = new_volume
        if i % 97 == 0:  # reset the cumulative volume everyday
            df.loc[i, 'CumulativeVolume'] = df.loc[i, 'Volume']
    df['VWAP'] = (((df['High'] + df['Low'] + df['Close']) / 3) * df['Volume']) / df['CumulativeVolume']

    df['LOW_EMA'] = talib.EMA(df['Close'], timeperiod=9)
    df['HIGH_EMA'] = talib.EMA(df['Close'], timeperiod=21)
    df['RSI'] = talib.RSI(df['Close'], timeperiod=14)
    df['Aroon'] = talib.AROONOSC(df['High'], df['Low'], timeperiod=14)
    df['Fast_%K'], df['Fast_%D'] = talib.STOCHF(df['High'], df['Low'], df['Close'], fastk_period=14)
    df['WILLR'] = talib.WILLR(df['High'], df['Low'], df['Close'])
    df['CCI'] = talib.CCI(df['High'], df['Low'], df['Close'])
    df['ATR'] = talib.ATR(df['High'], df['Low'], df['Close'])
    df['ADX'] = talib.ADX(df['High'], df['Low'], df['Close'])

    df['Momentum'] = df['Close'].diff()
    df['Absolute_Momentum'] = df['Momentum'].abs()
    df['Short_EMA_Momentum'] = talib.EMA(df['Momentum'], timeperiod=13)
    df['Short_EMA_Absolute'] = talib.EMA(df['Absolute_Momentum'], timeperiod=13)
    df['Double_EMA_Momentum'] = talib.EMA(df['Short_EMA_Momentum'], timeperiod=25)
    df['Double_EMA_Absolute'] = talib.EMA(df['Short_EMA_Absolute'], timeperiod=25)
    df['TSI'] = 100 * (df['Double_EMA_Momentum'] / df['Double_EMA_Absolute'])

    df['BB_Upper'], df['BB_Middle'], df['BB_Lower'] = talib.BBANDS(df['Close'], 20)
    df['BB_Width'] = df['BB_Upper'] - df['BB_Lower']

    macd, macdsignal, macdhist = talib.MACDFIX(df['Close'])
    df['MACD'] = macd
    df['MACDSignal'] = macdsignal
    df['MACDHist'] = macdhist

    df['PP'] = (df['High'].shift(1) + df['Low'].shift(1) + df['Close'].shift(1)) / 3
    df['R1'] = 2 * df['PP'] - df['Low'].shift(1)
    df['R2'] = df['PP'] + (df['High'].shift(1) - df['Low'].shift(1))
    df['S1'] = 2 * df['PP'] - df['High'].shift(1)
    df['S2'] = df['PP'] - (df['High'].shift(1) - df['Low'].shift(1))

    # Ichimoku Cloud
    df['Tenkan_Sen'] = (df['High'].rolling(window=9).max() + df['Low'].rolling(window=9).min()) / 2
    df['Kijun_Sen'] = (df['High'].rolling(window=26).max() + df['Low'].rolling(window=26).min()) / 2
    df['Senkou_Span_A'] = (df['Tenkan_Sen'] + df['Kijun_Sen']) / 2
    df['Senkou_Span_B'] = (df['High'].rolling(window=52).max() + df['Low'].rolling(window=52).min()) / 2
    df['Chikou_Span'] = df['Close'].shift(-26)

    # Keltner Channels
    df['KC_Middle'] = talib.EMA(df['Close'], timeperiod=20)
    df['KC_Upper'] = df['KC_Middle'] + df['ATR'] * 2
    df['KC_Lower'] = df['KC_Middle'] - df['ATR'] * 2
    df['KC_Width'] = df['KC_Upper'] - df['KC_Lower']

    # calculate interaction features
    df['Volume-ATR'] = df['Volume'] / df['ATR']
    df['VWAP-ATR'] = (df['Close'] - df['VWAP']) / df['ATR']
    df['RSI-MACD'] = df['RSI'] * df['MACD']
    df['Stochastic-RSI'] = df['Fast_%K'] / df['RSI']
    df['BB-KC'] = df['BB_Width'] / df['KC_Width']
    df['Ichimoku_Overlap'] = (df['Close'] - df['Kijun_Sen']) / (df['Senkou_Span_B'] - df['Senkou_Span_A'])
    df['LOW-HIGH_EMA'] = df['LOW_EMA'] / df['HIGH_EMA']

    df.replace([np.inf, -np.inf], 0, inplace=True)
    df.dropna(inplace=True)

    # Wave analysis
    n = 2
    df['Smoothed_Close'] = df['Close'].rolling(window=n).mean()

    max_indices = argrelextrema(df['Smoothed_Close'].values, np.greater_equal, order=n)[0]
    min_indices = argrelextrema(df['Smoothed_Close'].values, np.less_equal, order=n)[0]

    df['Wave_Amplitude'] = 0
    df['Wave_Direction'] = 0
    df['Wave_Length_Bars'] = 0

    last_peak_idx = 0
    last_trough_idx = 0

    for i in range(len(df)):
        idx = df.index[i]
        current_close = df['Smoothed_Close'].iloc[i]

        if last_trough_idx >= last_peak_idx:  # need this extra condition to make sure the amplitude and length are not overwritten by the peak code block (seperating peaks/troughs)
            trough_close = df['Smoothed_Close'].iloc[last_trough_idx]
            df.loc[idx, 'Wave_Amplitude'] = current_close - trough_close

            bars_length = i - last_trough_idx
            df.loc[idx, 'Wave_Length_Bars'] = bars_length

        if last_peak_idx >= last_trough_idx:
            peak_close = df['Smoothed_Close'].iloc[last_peak_idx]
            df.loc[idx, 'Wave_Amplitude'] = peak_close - current_close

            bars_length = i - last_peak_idx
            df.loc[idx, 'Wave_Length_Bars'] = bars_length

        if i in max_indices:
            df.loc[idx, 'Wave_Direction'] = -1
            last_peak_idx = i

        if i in min_indices:
            df.loc[idx, 'Wave_Direction'] = 1
            last_trough_idx = i

    # calculate extra wave features
    df['Wave_Velocity'] = df['Wave_Amplitude'] / (df['Wave_Length_Bars'] * 15)  # need the *15 because these features require the time from the last peak/trough
    df['Wave_Frequency'] = 1 / (df['Wave_Length_Bars'] * 15)
    df['Wave_Sharpness'] = df['Wave_Amplitude'] / ((df['Wave_Length_Bars'] * 15) ** 2)
    df['Wave_Slope'] = df['Wave_Amplitude'] / df['Wave_Length_Bars']
    df['Wave_Energy'] = df['Wave_Amplitude'] ** 2
    df['Wave_Acceleration'] = df['Wave_Slope'].diff() / df['Wave_Length_Bars']
    df['Wave_Strength'] = df['Wave_Slope'] * df['Wave_Direction']
    df['Normalized_Amplitude'] = df['Wave_Amplitude'] / df['Wave_Amplitude'].rolling(window=window_size).mean()
    df['Normalized_Slope'] = df['Wave_Slope'] / df['Wave_Slope'].rolling(window=window_size).mean()

    #df.dropna(subset=['Smoothed_Close'], inplace=True)
    # calculate aggregate features
    df['Close_Mean'] = df['Close'].rolling(window=window_size).mean()
    df['High_Mean'] = df['High'].rolling(window=window_size).mean()
    df['Open_Mean'] = df['Open'].rolling(window=window_size).mean()
    df['Low_Mean'] = df['Low'].rolling(window=window_size).mean()
    df['Volume_Mean'] = df['Volume'].rolling(window=window_size).mean()
    df['OBV_Mean'] = df['OBV'].rolling(window=window_size).mean()
    df['A/D_Mean'] = df['A/D'].rolling(window=window_size).mean()
    df['CMF_Mean'] = df['CMF'].rolling(window=window_size).mean()
    df['VWAP_Mean'] = df['VWAP'].rolling(window=window_size).mean()
    df['Returns_Mean'] = df['Returns'].rolling(window=window_size).mean()
    df['Volatility_Mean'] = df['Volatility'].rolling(window=window_size).mean()
    df['LOW_EMA_Mean'] = df['LOW_EMA'].rolling(window=window_size).mean()
    df['HIGH_EMA_Mean'] = df['HIGH_EMA'].rolling(window=window_size).mean()
    df['RSI_Mean'] = df['RSI'].rolling(window=window_size).mean()
    df['Aroon_Mean'] = df['Aroon'].rolling(window=window_size).mean()
    df['Fast_%K_Mean'] = df['Fast_%K'].rolling(window=window_size).mean()
    df['Fast_%D_Mean'] = df['Fast_%D'].rolling(window=window_size).mean()
    df['WILLR_Mean'] = df['WILLR'].rolling(window=window_size).mean()
    df['CCI_Mean'] = df['CCI'].rolling(window=window_size).mean()
    df['ATR_Mean'] = df['ATR'].rolling(window=window_size).mean()
    df['ADX_Mean'] = df['ADX'].rolling(window=window_size).mean()
    df['TSI_Mean'] = df['TSI'].rolling(window=window_size).mean()
    df['BB_Width_Mean'] = df['BB_Width'].rolling(window=window_size).mean()
    df['BB_Upper_Mean'] = df['BB_Upper'].rolling(window=window_size).mean()
    df['BB_Middle_Mean'] = df['BB_Middle'].rolling(window=window_size).mean()
    df['BB_Lower_Mean'] = df['BB_Lower'].rolling(window=window_size).mean()
    df['MACD_Mean'] = df['MACD'].rolling(window=window_size).mean()
    df['MACDSignal_Mean'] = df['MACDSignal'].rolling(window=window_size).mean()
    df['MACDHist_Mean'] = df['MACDHist'].rolling(window=window_size).mean()
    df['PP_Mean'] = df['PP'].rolling(window=window_size).mean()
    df['S1_Mean'] = df['S1'].rolling(window=window_size).mean()
    df['S2_Mean'] = df['S2'].rolling(window=window_size).mean()
    df['R1_Mean'] = df['R1'].rolling(window=window_size).mean()
    df['R2_Mean'] = df['R2'].rolling(window=window_size).mean()
    df['Tenkan_Sen_Mean'] = df['Tenkan_Sen'].rolling(window=window_size).mean()
    df['Kijun_Sen_Mean'] = df['Kijun_Sen'].rolling(window=window_size).mean()
    df['Senkou_Span_A_Mean'] = df['Senkou_Span_A'].rolling(window=window_size).mean()
    df['Senkou_Span_B_Mean'] = df['Senkou_Span_B'].rolling(window=window_size).mean()
    df['Chikou_Span_Mean'] = df['Chikou_Span'].rolling(window=window_size).mean()
    df['KC_Width_Mean'] = df['KC_Width'].rolling(window=window_size).mean()
    df['KC_Upper_Mean'] = df['KC_Upper'].rolling(window=window_size).mean()
    df['KC_Middle_Mean'] = df['KC_Middle'].rolling(window=window_size).mean()
    df['KC_Lower_Mean'] = df['KC_Lower'].rolling(window=window_size).mean()
    df['Wave_Direction_Mean'] = df['Wave_Direction'].rolling(window=window_size).mean()
    df['Wave_Amplitude_Mean'] = df['Wave_Amplitude'].rolling(window=window_size).mean()
    df['Wave_Velocity_Mean'] = df['Wave_Velocity'].rolling(window=window_size).mean()
    df['Wave_Frequency_Mean'] = df['Wave_Frequency'].rolling(window=window_size).mean()
    df['Wave_Sharpness_Mean'] = df['Wave_Sharpness'].rolling(window=window_size).mean()
    df['Wave_Slope_Mean'] = df['Wave_Slope'].rolling(window=window_size).mean()
    df['Wave_Energy_Mean'] = df['Wave_Energy'].rolling(window=window_size).mean()
    df['Wave_Acceleration_Mean'] = df['Wave_Acceleration'].rolling(window=window_size).mean()
    df['Wave_Strength_Mean'] = df['Wave_Strength'].rolling(window=window_size).mean()
    df['Volume-ATR_Mean'] = df['Volume-ATR'].rolling(window=window_size).mean()
    df['VWAP-ATR_Mean'] = df['VWAP-ATR'].rolling(window=window_size).mean()
    df['RSI-MACD_Mean'] = df['RSI-MACD'].rolling(window=window_size).mean()
    df['Stochastic-RSI_Mean'] = df['Stochastic-RSI'].rolling(window=window_size).mean()
    df['BB-KC_Mean'] = df['BB-KC'].rolling(window=window_size).mean()
    df['Ichimoku_Overlap_Mean'] = df['Ichimoku_Overlap'].rolling(window=window_size).mean()
    df['LOW-HIGH_EMA_Mean'] = df['LOW-HIGH_EMA'].rolling(window=window_size).mean()

    df['Close_Dev'] = df['Close'].rolling(window=window_size).std()
    df['High_Dev'] = df['High'].rolling(window=window_size).std()
    df['Open_Dev'] = df['Open'].rolling(window=window_size).std()
    df['Low_Dev'] = df['Low'].rolling(window=window_size).std()
    df['Volume_Dev'] = df['Volume'].rolling(window=window_size).std()
    df['OBV_Dev'] = df['OBV'].rolling(window=window_size).std()
    df['A/D_Dev'] = df['A/D'].rolling(window=window_size).std()
    df['CMF_Dev'] = df['CMF'].rolling(window=window_size).std()
    df['VWAP_Dev'] = df['VWAP'].rolling(window=window_size).std()
    df['Returns_Dev'] = df['Returns'].rolling(window=window_size).std()
    df['Volatility_Dev'] = df['Volatility'].rolling(window=window_size).std()
    df['LOW_EMA_Dev'] = df['LOW_EMA'].rolling(window=window_size).std()
    df['HIGH_EMA_Dev'] = df['HIGH_EMA'].rolling(window=window_size).std()
    df['RSI_Dev'] = df['RSI'].rolling(window=window_size).std()
    df['Aroon_Dev'] = df['Aroon'].rolling(window=window_size).std()
    df['Fast_%K_Dev'] = df['Fast_%K'].rolling(window=window_size).std()
    df['Fast_%D_Dev'] = df['Fast_%D'].rolling(window=window_size).std()
    df['WILLR_Dev'] = df['WILLR'].rolling(window=window_size).std()
    df['CCI_Dev'] = df['CCI'].rolling(window=window_size).std()
    df['ATR_Dev'] = df['ATR'].rolling(window=window_size).std()
    df['ADX_Dev'] = df['ADX'].rolling(window=window_size).std()
    df['TSI_Dev'] = df['TSI'].rolling(window=window_size).std()
    df['BB_Width_Dev'] = df['BB_Width'].rolling(window=window_size).std()
    df['BB_Upper_Dev'] = df['BB_Upper'].rolling(window=window_size).std()
    df['BB_Middle_Dev'] = df['BB_Middle'].rolling(window=window_size).std()
    df['BB_Lower_Dev'] = df['BB_Lower'].rolling(window=window_size).std()
    df['MACD_Dev'] = df['MACD'].rolling(window=window_size).std()
    df['MACDSignal_Dev'] = df['MACDSignal'].rolling(window=window_size).std()
    df['MACDHist_Dev'] = df['MACDHist'].rolling(window=window_size).std()
    df['PP_Dev'] = df['PP'].rolling(window=window_size).std()
    df['S1_Dev'] = df['S1'].rolling(window=window_size).std()
    df['S2_Dev'] = df['S2'].rolling(window=window_size).std()
    df['R1_Dev'] = df['R1'].rolling(window=window_size).std()
    df['R2_Dev'] = df['R2'].rolling(window=window_size).std()
    df['Tenkan_Sen_Dev'] = df['Tenkan_Sen'].rolling(window=window_size).std()
    df['Kijun_Sen_Dev'] = df['Kijun_Sen'].rolling(window=window_size).std()
    df['Senkou_Span_A_Dev'] = df['Senkou_Span_A'].rolling(window=window_size).std()
    df['Senkou_Span_B_Dev'] = df['Senkou_Span_B'].rolling(window=window_size).std()
    df['Chikou_Span_Dev'] = df['Chikou_Span'].rolling(window=window_size).std()
    df['KC_Width_Dev'] = df['KC_Width'].rolling(window=window_size).std()
    df['KC_Upper_Dev'] = df['KC_Upper'].rolling(window=window_size).std()
    df['KC_Middle_Dev'] = df['KC_Middle'].rolling(window=window_size).std()
    df['KC_Lower_Dev'] = df['KC_Lower'].rolling(window=window_size).std()
    df['Wave_Direction_Dev'] = df['Wave_Direction'].rolling(window=window_size).std()
    df['Wave_Amplitude_Dev'] = df['Wave_Amplitude'].rolling(window=window_size).std()
    df['Wave_Velocity_Dev'] = df['Wave_Velocity'].rolling(window=window_size).std()
    df['Wave_Frequency_Dev'] = df['Wave_Frequency'].rolling(window=window_size).std()
    df['Wave_Sharpness_Dev'] = df['Wave_Sharpness'].rolling(window=window_size).std()
    df['Wave_Slope_Dev'] = df['Wave_Slope'].rolling(window=window_size).std()
    df['Wave_Energy_Dev'] = df['Wave_Energy'].rolling(window=window_size).std()
    df['Wave_Acceleration_Dev'] = df['Wave_Acceleration'].rolling(window=window_size).std()
    df['Wave_Strength_Dev'] = df['Wave_Strength'].rolling(window=window_size).std()
    df['Volume-ATR_Dev'] = df['Volume-ATR'].rolling(window=window_size).std()
    df['VWAP-ATR_Dev'] = df['VWAP-ATR'].rolling(window=window_size).std()
    df['RSI-MACD_Dev'] = df['RSI-MACD'].rolling(window=window_size).std()
    df['Stochastic-RSI_Dev'] = df['Stochastic-RSI'].rolling(window=window_size).std()
    df['BB-KC_Dev'] = df['BB-KC'].rolling(window=window_size).std()
    df['Ichimoku_Overlap_Dev'] = df['Ichimoku_Overlap'].rolling(window=window_size).std()
    df['LOW-HIGH_EMA_Dev'] = df['LOW-HIGH_EMA'].rolling(window=window_size).std()

    df['Close_Drawdown'] = (df['Close'] / df['Close'].rolling(window=window_size).max() - 1).rolling(
        window=window_size).min()
    df['High_Drawdown'] = (df['High'] / df['High'].rolling(window=window_size).max() - 1).rolling(
        window=window_size).min()
    df['Open_Drawdown'] = (df['Open'] / df['Open'].rolling(window=window_size).max() - 1).rolling(
        window=window_size).min()
    df['Low_Drawdown'] = (df['Low'] / df['Low'].rolling(window=window_size).max() - 1).rolling(window=window_size).min()
    df['Volume_Drawdown'] = (df['Volume'] / df['Volume'].rolling(window=window_size).max() - 1).rolling(
        window=window_size).min()
    df['OBV_Drawdown'] = (df['OBV'] / df['OBV'].rolling(window=window_size).max() - 1).rolling(window=window_size).min()
    df['A/D_Drawdown'] = (df['A/D'] / df['A/D'].rolling(window=window_size).max() - 1).rolling(window=window_size).min()
    df['Volatility_Drawdown'] = (df['Volatility'] / df['Volatility'].rolling(window=window_size).max() - 1).rolling(
        window=window_size).min()
    df['LOW_EMA_Drawdown'] = (df['LOW_EMA'] / df['LOW_EMA'].rolling(window=window_size).max() - 1).rolling(
        window=window_size).min()
    df['HIGH_EMA_Drawdown'] = (df['HIGH_EMA'] / df['HIGH_EMA'].rolling(window=window_size).max() - 1).rolling(
        window=window_size).min()
    df['RSI_Drawdown'] = (df['RSI'] / df['RSI'].rolling(window=window_size).max() - 1).rolling(window=window_size).min()
    df['Fast_%K_Drawdown'] = (df['Fast_%K'] / df['Fast_%K'].rolling(window=window_size).max() - 1).rolling(
        window=window_size).min()
    df['Fast_%D_Drawdown'] = (df['Fast_%D'] / df['Fast_%D'].rolling(window=window_size).max() - 1).rolling(
        window=window_size).min()
    df['CCI_Drawdown'] = (df['CCI'] / df['CCI'].rolling(window=window_size).max() - 1).rolling(window=window_size).min()
    df['ATR_Drawdown'] = (df['ATR'] / df['ATR'].rolling(window=window_size).max() - 1).rolling(window=window_size).min()
    df['ADX_Drawdown'] = (df['ADX'] / df['ADX'].rolling(window=window_size).max() - 1).rolling(window=window_size).min()
    df['TSI_Drawdown'] = (df['TSI'] / df['TSI'].rolling(window=window_size).max() - 1).rolling(window=window_size).min()
    df['BB_Width_Drawdown'] = (df['BB_Width'] / df['BB_Width'].rolling(window=window_size).max() - 1).rolling(
        window=window_size).min()
    df['BB_Upper_Drawdown'] = (df['BB_Upper'] / df['BB_Upper'].rolling(window=window_size).max() - 1).rolling(
        window=window_size).min()
    df['BB_Middle_Drawdown'] = (df['BB_Middle'] / df['BB_Middle'].rolling(window=window_size).max() - 1).rolling(
        window=window_size).min()
    df['BB_Lower_Drawdown'] = (df['BB_Lower'] / df['BB_Lower'].rolling(window=window_size).max() - 1).rolling(
        window=window_size).min()
    df['MACD_Drawdown'] = (df['MACD'] / df['MACD'].rolling(window=window_size).max() - 1).rolling(
        window=window_size).min()
    df['MACDSignal_Drawdown'] = (df['MACDSignal'] / df['MACDSignal'].rolling(window=window_size).max() - 1).rolling(
        window=window_size).min()
    df['MACDHist_Drawdown'] = (df['MACDHist'] / df['MACDHist'].rolling(window=window_size).max() - 1).rolling(
        window=window_size).min()
    df['PP_Drawdown'] = (df['PP'] / df['PP'].rolling(window=window_size).max() - 1).rolling(window=window_size).min()
    df['S1_Drawdown'] = (df['S1'] / df['S1'].rolling(window=window_size).max() - 1).rolling(window=window_size).min()
    df['S2_Drawdown'] = (df['S2'] / df['S2'].rolling(window=window_size).max() - 1).rolling(window=window_size).min()
    df['R1_Drawdown'] = (df['R1'] / df['R1'].rolling(window=window_size).max() - 1).rolling(window=window_size).min()
    df['R2_Drawdown'] = (df['R2'] / df['R2'].rolling(window=window_size).max() - 1).rolling(window=window_size).min()
    df['Tenkan_Sen_Drawdown'] = (df['Tenkan_Sen'] / df['Tenkan_Sen'].rolling(window=window_size).max() - 1).rolling(
        window=window_size).min()
    df['Kijun_Sen_Drawdown'] = (df['Kijun_Sen'] / df['Kijun_Sen'].rolling(window=window_size).max() - 1).rolling(
        window=window_size).min()
    df['Senkou_Span_A_Drawdown'] = (
                df['Senkou_Span_A'] / df['Senkou_Span_A'].rolling(window=window_size).max() - 1).rolling(
        window=window_size).min()
    df['Senkou_Span_B_Drawdown'] = (
                df['Senkou_Span_B'] / df['Senkou_Span_B'].rolling(window=window_size).max() - 1).rolling(
        window=window_size).min()
    df['Chikou_Span_Drawdown'] = (df['Chikou_Span'] / df['Chikou_Span'].rolling(window=window_size).max() - 1).rolling(
        window=window_size).min()
    df['KC_Width_Drawdown'] = (df['KC_Width'] / df['KC_Width'].rolling(window=window_size).max() - 1).rolling(
        window=window_size).min()
    df['KC_Upper_Drawdown'] = (df['KC_Upper'] / df['KC_Upper'].rolling(window=window_size).max() - 1).rolling(
        window=window_size).min()
    df['KC_Middle_Drawdown'] = (df['KC_Middle'] / df['KC_Middle'].rolling(window=window_size).max() - 1).rolling(
        window=window_size).min()
    df['KC_Lower_Drawdown'] = (df['KC_Lower'] / df['KC_Lower'].rolling(window=window_size).max() - 1).rolling(
        window=window_size).min()
    df['Volume-ATR_Drawdown'] = (df['Volume-ATR'] / df['Volume-ATR'].rolling(window=window_size).max() - 1).rolling(
        window=window_size).min()
    df['VWAP-ATR_Drawdown'] = (df['VWAP-ATR'] / df['VWAP-ATR'].rolling(window=window_size).max() - 1).rolling(
        window=window_size).min()
    df['RSI-MACD_Drawdown'] = (df['RSI-MACD'] / df['RSI-MACD'].rolling(window=window_size).max() - 1).rolling(
        window=window_size).min()
    df['BB-KC_Drawdown'] = (df['BB-KC'] / df['BB-KC'].rolling(window=window_size).max() - 1).rolling(
        window=window_size).min()
    df['LOW-HIGH_EMA_Drawdown'] = (
                df['LOW-HIGH_EMA'] / df['LOW-HIGH_EMA'].rolling(window=window_size).max() - 1).rolling(
        window=window_size).min()

    df['Fast_%K_Drawdown'] = df['Fast_%K_Drawdown'].fillna(0)
    df[['Normalized_Amplitude', 'Normalized_Slope']] = df[['Normalized_Amplitude', 'Normalized_Slope']].fillna(0)
    df.dropna(inplace=True)

    #defragmenting the dataframe
    df = df.copy()

    return df

def convert_data_to_windows(data, window_size=2):
    rows = []
    for i in range(len(data) - window_size - 1):
        row = {}

        for feature in data.columns:
            if feature != 'Label':
                for t in range(window_size):
                    row[f"{feature}_t-{window_size-t}"] = data[feature].iloc[i + t + 1]

        row['Label'] = data['Label'].iloc[i + window_size + 1]
        rows.append(row)

    window_data = pd.DataFrame(rows)

    return window_data

def trading_simulation(probs, closes, buy_percentage, sell_percentage, starting_money=500, spend_percentage=0.1):
    money = starting_money
    bitcoin = 0
    probabilities = probs
    close_prices = closes
    sell_order = False
    buy_order = False
    previous_trade_assets = money

    #0 is sell, 2 is buy
    count = 0
    overconfidence = 0
    for probability in probabilities:
        if probability[0] >= sell_percentage:
            sell_order = True
        elif probability[2] >= buy_percentage:
            overconfidence = (probability[2] - buy_percentage) * 10
            print('Overconfidence: ' + str(overconfidence))
            buy_order = True

        if sell_order and probability[2] >= sell_percentage:
            money += bitcoin * close_prices[count]
            print(f"Sold {bitcoin} bitcoin at {close_prices[count]}")
            bitcoin = 0
            sell_order = False
            # total_assets = money + bitcoin * close_prices[count]
            # if total_assets < previous_trade_assets:
            #     print("Loss detected on this trade. Stopping simulation.")
            #     break
            # previous_trade_assets = total_assets

        if buy_order and probability[0] >= buy_percentage:
            bitcoin += money * (spend_percentage + overconfidence) / close_prices[count]
            money -= money * (spend_percentage + overconfidence)
            buy_order = False
            print(f"Bought {bitcoin} bitcoin at {close_prices[count]}")
            # total_assets = money + bitcoin * close_prices[count]
            # if total_assets < previous_trade_assets:
            #     print("Loss detected on this trade. Stopping simulation.")
            #     break
            # previous_trade_assets = total_assets

        print(f"Money: {money}, Bitcoin: {bitcoin}, Count: {count}")
        count += 1

    total_assets = money + bitcoin * close_prices[count-1]
    print("Final money: ", total_assets)
    print("Profit: ", total_assets - starting_money)

def get_next_interval(interval_seconds):
    now = time.time()
    next_interval = ((now // interval_seconds) + 1) * interval_seconds
    return next_interval - now

print("Starting main execution...")
window_size = 10
data_train, data_eval, data_test = load_and_preprocess_data("BTCUSDC15m_2020-2025_labeled.csv", window_size)
scaler = StandardScaler()
hmm_features = ["Open", "High", "Low", "Close", "Volume", "Volume_Change", "OBV", "A/D", "CMF", "VWAP", "RSI", "Aroon", 'Fast_%K', 'Fast_%D', 'WILLR', 'CCI', 'ATR', 'ADX', 'TSI', "BB_Width", "MACD", "MACDSignal", "MACDHist", "Volatility", "Returns"]
xg_features = ["Open", "High", "Low", "Close", "Volume", "Volume_Change", "OBV", "A/D", "CMF", "Returns", "Volatility", "LOW_EMA", "HIGH_EMA", "RSI", "Aroon", 'Fast_%K', 'Fast_%D', 'WILLR', 'CCI', 'ATR', 'ADX', 'TSI', 'BB_Upper', 'BB_Middle', 'BB_Lower',
               "BB_Width", "MACD", "MACDSignal", "MACDHist", "PP", "R1", "R2", "S1", "S2", 'Tenkan_Sen', 'Kijun_Sen', 'Senkou_Span_A', 'Senkou_Span_B', 'Chikou_Span', 'KC_Upper', 'KC_Middle', 'KC_Lower', 'KC_Width', 'Volume-ATR', 'VWAP-ATR', 'RSI-MACD',
               'Stochastic-RSI', 'BB-KC', 'Ichimoku_Overlap', 'LOW-HIGH_EMA', "Wave_Direction", "Wave_Amplitude", "Wave_Length_Bars", "Wave_Velocity", "Wave_Frequency", "Wave_Sharpness", "Wave_Slope", "Wave_Energy", "Wave_Acceleration", "Wave_Strength",
               "Normalized_Slope", "Normalized_Amplitude", "Label"]
agg_features = ["Open_Mean", "High_Mean", "Low_Mean", "Close_Mean", "Volume_Mean", "OBV_Mean", "A/D_Mean", "CMF_Mean", "VWAP_Mean", "Returns_Mean", "Volatility_Mean", "LOW_EMA_Mean", "HIGH_EMA_Mean", "RSI_Mean", "Aroon_Mean", 'Fast_%K_Mean', 'Fast_%D_Mean',
                'WILLR_Mean', 'CCI_Mean', 'ATR_Mean', 'ADX_Mean', 'TSI_Mean', 'BB_Upper_Mean', 'BB_Middle_Mean', 'BB_Lower_Mean', "BB_Width_Mean", "MACD_Mean", "MACDSignal_Mean", "MACDHist_Mean", "PP_Mean", "R1_Mean", "R2_Mean", "S1_Mean", "S2_Mean", 'Tenkan_Sen_Mean',
                'Kijun_Sen_Mean', 'Senkou_Span_A_Mean', 'Senkou_Span_B_Mean', 'Chikou_Span_Mean', 'KC_Upper_Mean', 'KC_Middle_Mean', 'KC_Lower_Mean', 'KC_Width_Mean', 'Volume-ATR_Mean', 'VWAP-ATR_Mean', 'RSI-MACD_Mean', 'Stochastic-RSI_Mean', 'BB-KC_Mean', 'Ichimoku_Overlap_Mean',
                'LOW-HIGH_EMA_Mean', "Wave_Direction_Mean", "Wave_Amplitude_Mean", "Wave_Velocity_Mean", "Wave_Frequency_Mean", "Wave_Sharpness_Mean", "Wave_Slope_Mean", "Wave_Energy_Mean", "Wave_Acceleration_Mean", "Wave_Strength_Mean", "Open_Dev", "High_Dev", "Low_Dev",
                "Close_Dev", "Volume_Dev", "OBV_Dev", "A/D_Dev", "CMF_Dev", "VWAP_Dev", "Returns_Dev", "Volatility_Dev", "LOW_EMA_Dev", "HIGH_EMA_Dev", "RSI_Dev", "Aroon_Dev", 'Fast_%K_Dev', 'Fast_%D_Dev', 'WILLR_Dev', 'CCI_Dev', 'ATR_Dev', 'ADX_Dev', 'TSI_Dev', 'BB_Upper_Dev',
                'BB_Middle_Dev', 'BB_Lower_Dev', "BB_Width_Dev", "MACD_Dev", "MACDSignal_Dev", "MACDHist_Dev", "PP_Dev", "R1_Dev", "R2_Dev", "S1_Dev", "S2_Dev", 'Tenkan_Sen_Dev', 'Kijun_Sen_Dev', 'Senkou_Span_A_Dev', 'Senkou_Span_B_Dev', 'Chikou_Span_Dev', 'KC_Upper_Dev', 'KC_Middle_Dev',
                'KC_Lower_Dev', 'KC_Width_Dev', 'Volume-ATR_Dev', 'VWAP-ATR_Dev', 'RSI-MACD_Dev', 'Stochastic-RSI_Dev', 'BB-KC_Dev', 'Ichimoku_Overlap_Dev', 'LOW-HIGH_EMA_Dev', "Wave_Direction_Dev", "Wave_Amplitude_Dev", "Wave_Velocity_Dev", "Wave_Frequency_Dev", "Wave_Sharpness_Dev",
                "Wave_Slope_Dev", "Wave_Energy_Dev", "Wave_Acceleration_Dev", "Wave_Strength_Dev", "Open_Drawdown", "High_Drawdown", "Low_Drawdown", "Close_Drawdown", "Volume_Drawdown", "OBV_Drawdown", "A/D_Drawdown", "Volatility_Drawdown", "LOW_EMA_Drawdown", "HIGH_EMA_Drawdown",
                "RSI_Drawdown", 'Fast_%K_Drawdown', 'Fast_%D_Drawdown', 'CCI_Drawdown', 'ATR_Drawdown', 'ADX_Drawdown', 'TSI_Drawdown', 'BB_Upper_Drawdown', 'BB_Middle_Drawdown', 'BB_Lower_Drawdown', "BB_Width_Drawdown", "MACD_Drawdown","MACDSignal_Drawdown", "MACDHist_Drawdown",
                "PP_Drawdown", "R1_Drawdown", "R2_Drawdown", "S1_Drawdown", "S2_Drawdown", 'Tenkan_Sen_Drawdown', 'Kijun_Sen_Drawdown', 'Senkou_Span_A_Drawdown', 'Senkou_Span_B_Drawdown', 'Chikou_Span_Drawdown', 'KC_Upper_Drawdown', 'KC_Middle_Drawdown', 'KC_Lower_Drawdown',
                'KC_Width_Drawdown', 'Volume-ATR_Drawdown', 'VWAP-ATR_Drawdown', 'RSI-MACD_Drawdown', 'BB-KC_Drawdown', 'LOW-HIGH_EMA_Drawdown']

hmm_path = train_hmm(data_train, hmm_features, scaler, 12)
hmm_model = load_hmm(hmm_path)
print("Predicting states...")
states = predict_states(hmm_model, data_train, hmm_features, scaler)
states_eval = predict_states(hmm_model, data_eval, hmm_features, scaler)
states_out = predict_states(hmm_model, data_test, hmm_features, scaler)
data_train['State'] = states
data_eval['State'] = states_eval
data_test['State'] = states_out

#defragmenting the dataframes
data_train = data_train.copy()
data_eval = data_eval.copy()
data_test = data_test.copy()

#Build xgboost model
xg_data_train = convert_data_to_windows(data_train[xg_features], window_size)
xg_data_eval = convert_data_to_windows(data_eval[xg_features], window_size)
xg_data_test = convert_data_to_windows(data_test[xg_features], window_size)
#dropping the first few rows to line up data with the xgboost data
data_train = data_train.drop(index=data_train.index[:window_size])
data_eval = data_eval.drop(index=data_eval.index[:window_size])
data_test = data_test.drop(index=data_test.index[:window_size])

#need to reset index so that the concat works properly
xg_data_train = xg_data_train.reset_index(drop=True)
data_train = data_train.reset_index(drop=True)
xg_data_eval = xg_data_eval.reset_index(drop=True)
data_eval = data_eval.reset_index(drop=True)
xg_data_test = xg_data_test.reset_index(drop=True)
data_test = data_test.reset_index(drop=True)
xg_data_train = pd.concat([xg_data_train, data_train[agg_features]], axis=1)
xg_data_eval = pd.concat([xg_data_eval, data_eval[agg_features]], axis=1)
xg_data_test = pd.concat([xg_data_test, data_test[agg_features]], axis=1)

xg_data_train.dropna(inplace=True)
xg_data_eval.dropna(inplace=True)
xg_data_test.dropna(inplace=True)

xg_labels_train = xg_data_train.pop('Label').tolist()
xg_labels_train = [int(x) for x in xg_labels_train]
xg_labels_eval = xg_data_eval.pop('Label').tolist()
xg_labels_eval = [int(x) for x in xg_labels_eval]
xg_labels_test = xg_data_test.pop('Label').tolist()
xg_labels_test = [int(x) for x in xg_labels_test]

print("Unique labels:", set(xg_labels_train))

xgboost_path = train_xgboost(xg_data_train, xg_labels_train, xg_data_eval, xg_labels_eval, 10, 30)
#xgboost_path = "xgboost_pipeline.pkl"
xgboost_model = load_xgboost(xgboost_path)
xg_labels_pred = xgboost_model.predict(xg_data_test)
xg_labels_pred = xg_labels_pred.tolist()

#Filtering lists so that there is only entries where either the real list or the predicted list has a 0 or 2 in them
#Since buying and selling are the more important predictions in an actual algo trader I want to see only the buy/sell accuracy
buy_sell_label, buy_sell_label_pred = zip(*[(x, y) for x, y in zip(xg_labels_test, xg_labels_pred) if (x in [0, 2] or y in [0, 2])])
buy_sell_label = list(buy_sell_label)
buy_sell_label_pred = list(buy_sell_label_pred)
buy_sell_accuracy = accuracy_score(buy_sell_label, buy_sell_label_pred)
print(f"buy_sell accuracy: {buy_sell_accuracy}")

recent_df = get_historical_data(1735707600000, 1737090000000)
recent_df = calculate_indicators(recent_df)
recent_df = recent_df.dropna()
recent_df['State'] = predict_states(hmm_model, recent_df, hmm_features, scaler)

#Need this to make recent_df compatible with convert_data_to_windows method
recent_df['Label'] = 0
recent_df_windowed = convert_data_to_windows(recent_df[xg_features], window_size)

recent_df = recent_df.drop(index=recent_df.index[:window_size])
recent_df = recent_df.reset_index(drop=True)
recent_df_windowed = recent_df_windowed.reset_index(drop=True)
recent_df = pd.concat([recent_df_windowed, recent_df[agg_features]], axis=1)
recent_df.drop(['Label'], axis=1, inplace=True)

probabilities = xgboost_model.predict_proba(recent_df).tolist()
probability_0 = []
probability_1 = []
probability_2 = []
for probability in probabilities:
    probability_0.append(probability[0])
    probability_1.append(probability[1])
    probability_2.append(probability[2])

print(f"75th percentile of sells: {np.percentile(probability_0, 57)}")
print(f"75th percentile of holds: {np.percentile(probability_1, 57)}")
print(f"75th percentile of buys: {np.percentile(probability_2, 57)}")
closes = recent_df['Close_t-1'].tolist()
trading_simulation(probabilities, closes, np.percentile(probability_2, 55), np.percentile(probability_0, 55), starting_money=1500, spend_percentage=0.2)
#while True:
#     start_time = time.time()
#
#     recent_df = calculate_indicators(recent_df)
#     recent_df = recent_df.dropna()
#     recent_df['State'] = predict_states(hmm_model, recent_df, hmm_features, scaler)
#
#     #Need this to make recent_df compatible with convert_data_to_windows method
#     recent_df['Label'] = 0
#     recent_df_windowed = convert_data_to_windows(recent_df[xg_features], window_size)
#
#     recent_df = recent_df.drop(index=recent_df.index[:window_size])
#     recent_df = recent_df.reset_index(drop=True)
#     recent_df_windowed = recent_df_windowed.reset_index(drop=True)
#     recent_df = pd.concat([recent_df_windowed, recent_df[agg_features]], axis=1)
#     print(recent_df)
#     recent_df.drop(['Label'], axis=1, inplace=True)
#
#     labels_recent_pred = xgboost_model.predict(recent_df)
#     labels_recent_pred = labels_recent_pred.tolist()
#     recent_df['Label'] = labels_recent_pred
#     recent_df['PriceDiff'] = recent_df['Close_t-1'].diff()
#
#     trading_df = recent_df[['Close_t-1', 'Label']]
#     print(trading_df)
#
#     time.sleep(180)
#     recent_df = get_historical_data(54)
